groups:
  - id: registry.gen_ai
    type: attribute_group
    display_name: GenAI Attributes
    brief: >
      This document defines the attributes used to describe telemetry in the context of Generative Artificial Intelligence (GenAI) Models requests and responses.
    attributes:
      - id: gen_ai.system
        stability: experimental
        type:
          members:
            - id: openai
              stability: experimental
              value: "openai"
              brief: 'OpenAI'
            - id: vertex_ai
              stability: experimental
              value: "vertex_ai"
              brief: 'Vertex AI'
            - id: anthropic
              stability: experimental
              value: "anthropic"
              brief: 'Anthropic'
            - id: cohere
              stability: experimental
              value: "cohere"
              brief: 'Cohere'
            - id: az.ai.inference
              stability: experimental
              value: "az.ai.inference"
              brief: 'Azure AI Inference'
        brief: The Generative AI product as identified by the client or server instrumentation.
        note: |
          The `gen_ai.system` describes a family of GenAI models with specific model identified
          by `gen_ai.request.model` and `gen_ai.response.model` attributes.

          The actual GenAI product may differ from the one identified by the client.
          For example, when using OpenAI client libraries to communicate with Mistral, the `gen_ai.system`
          is set to `openai` based on the instrumentation's best knowledge.

          For custom model, a custom friendly name SHOULD be used.
          If none of these options apply, the `gen_ai.system` SHOULD be set to `_OTHER`.
        examples: 'openai'
      - id: gen_ai.request.model
        stability: experimental
        type: string
        brief: The name of the GenAI model a request is being made to.
        examples: 'gpt-4'
      - id: gen_ai.request.max_output_tokens
        stability: experimental
        type: int
        brief: The maximum number of completion tokens the model generates in response.
        examples: [100]
      - id: gen_ai.request.max_input_tokens
        stability: experimental
        type: int
        brief: The maximum number of prompt tokens the model can use.
        examples: [100]
      - id: gen_ai.request.temperature
        stability: experimental
        type: double
        brief: The temperature setting for the GenAI request.
        examples: [0.0]
      - id: gen_ai.request.top_p
        stability: experimental
        type: double
        brief: The top_p sampling setting for the GenAI request.
        examples: [1.0]
      - id: gen_ai.request.top_k
        stability: experimental
        type: double
        brief: The top_k sampling setting for the GenAI request.
        examples: [1.0]
      - id: gen_ai.request.stop_sequences
        stability: experimental
        type: string[]
        brief: List of sequences that the model will use to stop generating further tokens.
        examples:
          - [forest, lived]
      - id: gen_ai.request.frequency_penalty
        stability: experimental
        type: double
        brief: The frequency penalty setting for the GenAI request.
        examples: [0.1]
      - id: gen_ai.request.presence_penalty
        stability: experimental
        type: double
        brief: The presence penalty setting for the GenAI request.
        examples: [0.1]
      - id: gen_ai.response.id
        stability: experimental
        type: string
        brief: The unique identifier for the completion.
        examples: ['chatcmpl-123']
      - id: gen_ai.response.model
        stability: experimental
        type: string
        brief: The name of the model that generated the response.
        examples: ['gpt-4-0613']
      - id: gen_ai.response.finish_reasons
        stability: experimental
        type: string[]
        brief: Array of reasons the model stopped generating tokens, corresponding to each generation received.
        examples:
          - [stop]
          - [stop, length]
      - id: gen_ai.usage.input_tokens
        stability: experimental
        type: int
        brief: The number of tokens used in the GenAI input (prompt).
        examples: [100]
      - id: gen_ai.usage.output_tokens
        stability: experimental
        type: int
        brief: The number of tokens used in the GenAI response (completion).
        examples: [180]
      - id: gen_ai.token.type
        stability: experimental
        type:
          members:
            - id: input
              stability: experimental
              value: "input"
              brief: 'Input tokens (prompt, input, etc.)'
            - id: completion
              stability: experimental
              value: "output"
              brief: 'Output tokens (completion, response, etc.)'
        brief: The type of token being counted.
        examples: ['input', 'output']
      - id: gen_ai.operation.name
        stability: experimental
        type:
          members:
            - id: chat
              value: "chat"
              brief: 'Chat completion operation such as [OpenAI Chat API](https://platform.openai.com/docs/api-reference/chat)'
              stability: experimental
            - id: create_thread_run
              value: "create_thread_run"
              brief: 'Create a run on a thread'
              note: >
                This operation describes creating a run.
                The run can consist of multiple steps (such as GenAI chat calls) which may
                be executed locally on the the client by a GenAI client framework or
                remotely on the GenAI agent.

                Unlike `run` this operation covers the creation of the thread run
                and does not include time awaiting the completion of the run.

                Instrumentations SHOULD report `run` operation instead of `create_run`
                whenever possible.
              stability: experimental
            - id: thread_run
              value: "thread_run"
              brief: 'Run a thread on an agent'
              note: >
                This operation describes creating and processing a thread run on an agent.

                The run can consist of multiple steps (such as GenAI chat calls) which may
                be executed locally on the the client by a GenAI client framework or
                remotely on the GenAI agent.

                The instrumented operation SHOULD cover full duration of the run
                including time awaiting the final completion. It SHOULD be reported
                for streaming runs, or for operations that involve polling the status.
              stability: experimental
            - id: submit_tool_output
              value: "submit_tool_output"
              brief: 'Submit tool call results to a run'
              note: >
                This operation describes submitting tool output to the run.
              stability: experimental
            - id: tool_execution
              value: "tool_execution"
              brief: 'Submit tool call results to a run'
              note: >
                This operation describes a specific tool execution.
              stability: experimental
            - id: text_completion
              value: "text_completion"
              brief: 'Text completions operation such as [OpenAI Completions API (Legacy)](https://platform.openai.com/docs/api-reference/completions)'
              stability: experimental
        brief: The name of the operation being performed.
        note: >
          If one of the predefined values applies, but specific system uses a different name it's RECOMMENDED to document it in the semantic
          conventions for specific GenAI system and use system-specific name in the instrumentation.
          If a different name is not documented, instrumentation libraries SHOULD use applicable predefined value.
      - id: gen_ai.agent.name
        stability: experimental
        type: string
        brief: The name of the GenAI agent.
        examples: ['web_search', "travel_bot"]
      - id: gen_ai.agent.id
        stability: experimental
        type: string
        brief: The unique identifier of the GenAI agent.
        examples: ['asst_5j66UpCpwteGg4YSxUnt7lPY']
      - id: gen_ai.thread.id
        stability: experimental
        type: string
        brief: The unique identifier of the thread.
        examples: ['thread_ggguJ0iZXRPjUnCy9vT9Fdvs']
      - id: gen_ai.message.id
        stability: experimental
        type: string
        brief: The unique identifier of the message within a thread.
        examples: ['msg_sLMd7grQfjFXgu5ZeHCXmBr7']
      - id: gen_ai.message.status
        stability: experimental
        type:
          members:
            - id: in_progress
              value: "in_progress"
              brief: 'The message is in progress'
              stability: experimental
            - id: completed
              value: "completed"
              brief: 'The message has been completed'
              stability: experimental
            - id: incomplete
              value: "incomplete"
              brief: 'The message has ended due to reaching maximum number of input or output tokens'
              stability: experimental
        brief: The status of the message.
      - id: gen_ai.thread.run.id
        stability: experimental
        type: string
        brief: The unique identifier of the thread run.
        examples: ['run_ep8IxBKdM06Mv338KNyo6EKP']
      - id: gen_ai.thread.run.status
        stability: experimental
        type:
          members:
            - id: queued
              value: "queued"
              brief: 'The thread run is queued'
              stability: experimental
            - id: in_progress
              value: "in_progress"
              brief: 'The thread run is in progress'
              stability: experimental
            - id: completed
              value: "completed"
              brief: 'The thread run has completed'
              stability: experimental
            - id: incomplete
              value: "incomplete"
              brief: 'The thread run has ended due to reaching maximum number of input or output tokens'
              stability: experimental
            - id: requires_action
              value: "requires_action"
              brief: 'The thread run requires action.'
              stability: experimental
            - id: failed
              value: "failed"
              brief: 'The thread run has failed'
              stability: experimental
            - id: canceled
              value: "canceled"
              brief: 'The thread run has been canceled'
              stability: experimental
            - id: expired
              value: "expired"
              brief: 'The thread run has expired'
              stability: experimental
        brief: The thread run status
  - id: registry.gen_ai.openai
    type: attribute_group
    display_name: OpenAI Attributes
    brief: >
      Thie group defines attributes for OpenAI.
    attributes:
      - id: gen_ai.openai.request.seed
        stability: experimental
        type: int
        brief: Requests with same seed value more likely to return same result.
        examples: [100]
      - id: gen_ai.openai.request.response_format
        stability: experimental
        type:
          members:
            - id: text
              value: "text"
              brief: 'Text response format'
              stability: experimental
            - id: json_object
              value: "json_object"
              brief: 'JSON object response format'
              stability: experimental
            - id: json_schema
              value: "json_schema"
              brief: 'JSON schema response format'
              stability: experimental
        brief: The response format that is requested.
        examples: ['json']
      - id: gen_ai.openai.request.service_tier
        stability: experimental
        type:
          members:
            - id: auto
              value: "auto"
              brief: The system will utilize scale tier credits until they are exhausted.
              stability: experimental
            - id: default
              value: "default"
              brief: The system will utilize the default scale tier.
              stability: experimental
        brief: The service tier requested. May be a specific tier, detault, or auto.
        examples: ['auto', 'default']
      - id: gen_ai.openai.response.service_tier
        stability: experimental
        type: string
        brief: The service tier used for the response.
        examples: ['scale', 'detault']
