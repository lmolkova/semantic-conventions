groups:
  - id: registry.llm
    prefix: gen_ai.llm
    type: attribute_group
    brief: >
      This document defines the attributes used to describe telemetry in the context of LLM (Large Language Models) requests and responses.
    attributes:
      - id: system
        type: string
        brief: The name of the LLM foundation model vendor, if applicable.
        examples: 'openai'
        tag: llm-generic-request
      - id: request.model
        type: string
        brief: The name of the LLM a request is being made to.
        examples: 'gpt-4'
        tag: llm-generic-request
      - id: request.max_tokens
        type: int
        brief: The maximum number of tokens the LLM generates for a request.
        examples: [100]
        tag: llm-generic-request
      - id: request.temperature
        type: double
        brief: The temperature setting for the LLM request.
        examples: [0.0]
        tag: llm-generic-request
      - id: request.top_p
        type: double
        brief: The top_p sampling setting for the LLM request.
        examples: [1.0]
        tag: llm-generic-request
      - id: response.id
        type: string
        brief: The unique identifier for the completion.
        examples: ['chatcmpl-123']
        tag: llm-generic-response
      - id: response.model
        type: string
        brief: The name of the LLM a response is being made to.
        examples: ['gpt-4-0613']
        tag: llm-generic-response
      - id: response.finish_reason
        type: string[]
        brief: Array of reasons the model stopped generating tokens, corresponding to each generation received.
        examples: [['stop']]
        tag: llm-generic-response
      - id: usage.prompt_tokens
        type: int
        brief: The number of tokens used in the LLM prompt.
        examples: [100]
        tag: llm-generic-response
      - id: usage.completion_tokens
        type: int
        brief: The number of tokens used in the LLM response (completion).
        examples: [180]
        tag: llm-generic-response
      - id: prompt
        type: string
        brief: The full prompt sent to an LLM, as a stringified JSON in OpenAI's format.
        examples: ["[{'role': 'user', 'content': 'What is the capital of France?'}]"]
        tag: llm-generic-events
      - id: completion
        type: string
        brief:  The full response received from the LLM, as a stringified JSON in OpenAI's format.
        examples: ["[{'role': 'assistant', 'content': 'The capital of France is Paris.'}]"]
        tag: llm-generic-events
