groups:
  - id: attributes.openai
    prefix: openai
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI attributes.'
    attributes:
      - id: model
        type: string
        brief: 'Model name'
        examples: ['text-davinci-003']
        requirement_level: required
      - ref: server.address
        requirement_level: required
      - ref: error.type
        note: |
          The `error.type` SHOULD be predictable and SHOULD have low cardinality.
          Instrumentations SHOULD document the list of errors they report.

          The cardinality of `error.type` within one instrumentation library SHOULD be low, but
          telemetry consumers that aggregate data from multiple instrumentation libraries and applications
          should be prepared for `error.type` to have high cardinality at query time, when no
          additional filters are applied.

          If the operation has completed successfully, instrumentations SHOULD NOT set `error.type`.
        requirement_level:
          conditionally_required: if and only if operation has ended with an error

  - id: attributes.openai.metrics
    prefix: openai
    type: attribute_group
    brief: 'Semantic convention describing OpenAI metrics-specific attributes.'
    attributes:
      - id: usage.type
        type: string
        brief: 'Describes if tokens were used in prompt or completion'
        examples: ['prompt', 'completion']
      - id: choice.finish_reason
        type: string
        brief: 'Finish reason for single chat completion choice'
        examples: ['stop', 'length', 'content_filter']
      - id: choice.finish_reasons
        type: string[]
        brief: 'A list of finish reason for chat completion request'
        examples: ['stop, length, content_filter']

  - id: attributes.openai.azure
    prefix: openai.azure
    type: attribute_group
    brief: 'Semantic convention describing Azure-specific OpenAI attributes.'
    attributes:
      - id: chat_completions.response.filter_results
        type: string[]
        brief: 'Array of results that were filtered out.'
        examples: ['[1]: self_harm', '[2]: violence, hate']
        requirement_level:
          conditionally_required: if and only if some content was filtered

  - id: attributes.openai.chat_completions.request
    prefix: openai.chat_completions.request
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI chat completions request attributes.'
    attributes:
      - id: max_tokens
        type: int
        brief: 'The maximum number of tokens to generate in the completion.'
        examples: [1024]
      - id: temperature
        type: double
        brief: 'Sampling temperature, between 0 and 2'
        examples: [0.7]
      - id: top_p
        type: double
        brief: 'The nucleus sampling factor, between 0 and 1'
        examples: [0.1]
      - id: presence_penalty
        type: double
        brief: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear.'
        examples: [0.0]
      - id: frequency_penalty
        type: double
        brief: 'Number between -2.0 and 2.0.Positive values penalize new tokens based on their existing frequency.'
        examples: [0.0]

  - id: attributes.openai.chat_completions.response
    prefix: openai.chat_completions.response
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI chat completions response attributes.'
    attributes:
      - id: id
        type: string
        brief: 'A unique identifier for the chat completion.'
        examples: ['cmpl-7ykn0gf4r76hfDam5e7l0s05ZWSmA']
      - id: created_at
        type: int
        brief: 'The Unix timestamp (in seconds) of when the chat completion was created.'
        examples: [1677652288]

  - id: attributes.openai.usage
    prefix: openai.usage
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI usage attributes.'
    attributes:
      - id: prompt_tokens
        type: int
        brief: 'Number of tokens in the prompt.'
        examples: [9]
      - id: completion_tokens
        type: int
        brief: 'Number of tokens in the generated completion.'
        examples: [12]

  - id: attributes.openai.embeddings.request
    prefix: openai.embeddings.request
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI embeddings request attributes.'
    attributes:
      - id: input_size
        type: int
        brief: 'Size of input text to embed.'
        examples: [1024]

  - id: attributes.openai.embeddings.response
    prefix: openai.embeddings.response
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI embeddings response attributes.'
    attributes:
      - id: index
        type: int
        brief: 'The index of the embedding in the list of embeddings.'
        examples: [0]
      - id: vector_size
        type: int
        brief: 'The size of embedding vector'
        examples: [1536]

  - id: attributes.openai.image_generations.request
    prefix: openai.image_generations.request
    type: attribute_group
    brief: 'Semantic convention describing common OpenAI images generations request attributes.'
    attributes:
      - id: image_count
        type: int
        brief: 'The number of images to generate.'
        examples: [2]
      - id: image_size
        type: string
        brief: 'The size of the generated images.'
        examples: ['256x256']
      - id: image_format
        type: string
        brief: 'The format in which the generated images should be returned.'
        examples: ['b64_json']

  - id: trace.openai.chat_completions
    type: span
    extends: attributes.openai
    span_kind: client
    brief: 'Semantic Convention for OpenAI client chat completions spans'
    attributes:
      - ref: openai.chat_completions.request.max_tokens
      - ref: openai.chat_completions.request.temperature
      - ref: openai.chat_completions.request.top_p
      - ref: openai.chat_completions.request.presence_penalty
      - ref: openai.chat_completions.request.frequency_penalty
      - ref: openai.chat_completions.response.id
      - ref: openai.chat_completions.response.created_at
      - ref: openai.usage.prompt_tokens
      - ref: openai.usage.completion_tokens
      - ref: openai.choice.finish_reasons
      # TODO separate span for Azure
      - ref: openai.azure.chat_completions.response.filter_results

  - id: trace.openai.embeddings
    type: span
    extends: attributes.openai
    span_kind: client
    brief: 'Semantic Convention for OpenAI client embeddings spans'
    attributes:
      - ref: openai.embeddings.request.input_size
      - ref: openai.embeddings.response.index
      - ref: openai.embeddings.response.vector_size
      - ref: openai.usage.prompt_tokens

  - id: trace.openai.image_generations
    type: span
    extends: attributes.openai
    span_kind: client
    brief: 'Semantic Convention for OpenAI client image generations spans'
    attributes:
      - ref: openai.image_generations.request.image_count
      - ref: openai.image_generations.request.image_size
      - ref: openai.image_generations.request.image_format

  - id: metric.openai.chat_completions.tokens
    type: metric
    metric_name: openai.chat_completions.tokens
    brief: "Number of tokens used in prompt and completions"
    instrument: counter
    unit: "{token}"
    extends: attributes.openai
    attributes:
      - ref: openai.usage.type
        requirement_level: required

  - id: metric.openai.chat_completions.choices
    type: metric
    metric_name: openai.chat_completions.choices
    brief: "Number of choices returned by chat completions call"
    instrument: counter
    unit: "{choice}"
    extends: attributes.openai
    attributes:
      - ref: openai.usage.type
        requirement_level: required
      - ref: openai.choice.finish_reason
        requirement_level:
          conditionally_required: if and only if it was returned.

  - id: metric.openai.embeddings.tokens
    type: metric
    metric_name: openai.embeddings.tokens
    brief: "Number of tokens used in prompt."
    instrument: counter
    unit: "{token}"
    extends: attributes.openai
    attributes:
      - ref: openai.usage.type
        requirement_level: recommended
        examples: ['prompt']

  - id: metric.openai.embeddings.vector_size
    type: metric
    metric_name: openai.embeddings.vector_size
    brief: "The size of returned vector."
    instrument: counter
    unit: "{element}"
    extends: attributes.openai

  - id: metric.openai.chat_completions.duration
    type: metric
    metric_name: openai.chat_completions.duration
    brief: "Duration of chat completion operation"
    instrument: histogram
    unit: "s"
    extends: attributes.openai

  - id: metric.openai.embeddings.duration
    type: metric
    metric_name: openai.embeddings.duration
    brief: "Duration of embeddings operation"
    instrument: histogram
    unit: "s"
    extends: attributes.openai

  - id: metric.openai.image_generations.duration
    type: metric
    metric_name: openai.image_generations.duration
    brief: "Duration of image generations operation"
    instrument: histogram
    unit: "s"
    extends: attributes.openai